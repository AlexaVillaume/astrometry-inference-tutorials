rmarkdown::render_site()
# Create the data list object
dat = list(N = N, obsy=y.obs.samples, obsx=x.obs.samples,sigmaobsy=y.obs.errors,sigmaobsx=x.obs.errors)
N <- 3000
x.mu <- 3
x.sigma <- 0.5
x.samples <- rnorm(N, x.mu , x.sigma)
hist(x.samples,breaks=100,xlab="x",main="",freq=FALSE)
library(DiagrammeR)
grViz("
digraph BGMexample1 {
margin=0;
ratio=0.6;
compound=true;
node[style=filled,shape=circle,color=black, fillcolor=cadetblue3,fixedsize=false];
rankdir =TB;
subgraph cluster0 {
label='N';
# Observations
# https://github.com/rich-iannone/DiagrammeR/issues/71
x_rec[label='x&#770;@_{i}',shape=doublecircle];
}
# Parameters
mu[label='&mu;'];
sigma[label='&sigma;',shape=square];
# Links to observed nodes
mu -> x_rec;
sigma -> x_rec;
}
", width = 400, height = 400  )
library(rstan)
library(ggplot2)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
stanBGM1 <-'
data {
int<lower=0> N;
vector[N] obsx;
real<lower=0> sigma;
real<lower=0> sigma0;
}
parameters {
real mu;
}
model {
//prior
mu ~ normal(0, sigma0);
//likelihood
for (n in 1:N) {
obsx[n] ~ normal(mu, sigma);
}
}
'
# Load data
dat = list(N = N, obsx=x.samples, sigma=x.sigma, sigma0=100)
# Define a seed for repeatability
set.seed(12354)
# Start the MCMC chains (3) with 6000 steps from which the first 3000 will be
# assumed to serve for initial convergence (not representative of the posterior)
# and will be therefore discarded
fit1 <- stan(model_code = stanBGM1, data = dat, chains = 3,  iter = 6000  , warmup = 3000, verbose = FALSE)
# summary
print(fit1, digits_summary=4)
stan_trace(fit1,pars=c("mu"),unconstrain = FALSE)
stan_hist(fit1,pars=c("mu"),unconstrain = FALSE)
N <- 500
#Generate the samples as before
x.mu <- 3
x.sigma <- 0.5
x.samples <- rnorm(N, x.mu , x.sigma)
# Now make up some measurement uncertainties...
x.obs.errors <- rnorm(N,0,1)
x.obs.errors <- abs(x.obs.errors)
# ...and add measurement noise to the samples
x.obs.samples <- rnorm(N, x.samples, x.obs.errors)
hist(x.samples,breaks=100,xlab="x",main="",freq=FALSE,xlim=c(0,6),ylim=c(0,1))
hist(x.obs.samples,breaks=100,xlab="x",main="",freq=FALSE,xlim=c(0,6),ylim=c(0,1))
grViz("
digraph BGMexample2 {
margin=0;
ratio=0.6;
compound=true;
node[style=filled,shape=circle,color=black, fillcolor=gray,fixedsize=false];
rankdir =TB;
subgraph cluster0 {
label='N';
# Parameters
x[label='x@_{i}'];
# Observations
# https://github.com/rich-iannone/DiagrammeR/issues/71
x_rec[label='x&#770;@_{i}',shape=doublecircle,fillcolor=deepskyblue1];
}
# Hyperparameters
mu[label='&mu;',fillcolor=darkseagreen3];
sigma[label='&sigma;',fillcolor=darkseagreen3];
# Links
mu -> x;
sigma -> x;
x -> x_rec;
}
", width = 600, height = 600  )
stanBGM2 <-'
data {
int<lower=0> N;
vector[N] obsx;
vector<lower=0>[N] sigmaobsx;
}
parameters {
real mu;
real<lower=0> sigma;
vector[N] x;
}
model {
# hyperpriors
mu ~ normal(0, 10);
sigma ~ uniform(0, 10);
# priors
for (n in 1:N) {
x[n] ~ normal(mu, sigma);
# Likelihood
obsx[n] ~ normal(x[n], sigmaobsx[n]);
}
}
'
# Create the data list object
dat = list(N = N, obsx=x.obs.samples, sigmaobsx=x.obs.errors)
fit1 <- stan(model_code = stanBGM2, chains = 1, data = dat, iter = 1, verbose = FALSE)
set.seed(12354)
fit2 = stan(fit=fit1 , data = dat,  iter = 5000  , warmup = 3000, chains = 3)
# summary
print(fit2, pars=c("mu","sigma"), digits_summary=4)
stanBGM2pooled <-'
data {
int<lower=0> N;
vector[N] obsx;
vector<lower=0>[N] sigmaobsx;
}
parameters {
real mu;
}
model {
# priors
mu ~ normal(0, 10);
for (n in 1:N) {
# Likelihood
obsx[n] ~ normal(mu, sigmaobsx[n]);
}
}
'
# Create the data list object
dat = list(N = N, obsx=x.obs.samples, sigmaobsx=x.obs.errors)
fit21 <- stan(model_code = stanBGM2pooled, chains = 1, data = dat, iter = 1, verbose = FALSE)
set.seed(12354)
fit22 = stan(fit=fit21 , data = dat,  iter = 5000  , warmup = 3000, chains = 3)
# summary
print(fit22, digits_summary=4)
# Same scheme as before
N = 200
x.mu = -0.27790
x.sigma = 0.076
x.samples = rnorm(N, x.mu , x.sigma)
x.obs.errors <- rnorm(N,0,0.1)
x.obs.errors <- abs(x.obs.errors)
x.obs.samples <- rnorm(N, x.samples, x.obs.errors)
# Now, let us define the predicted variable
y.slope = -2.73
y.intercept = -1.24
y.sigma = 0.05
y.samples = rnorm(N, y.slope*x.samples + y.intercept , y.sigma)
y.obs.errors <- rnorm(N,0,0.1)
y.obs.errors <- abs(y.obs.errors)
y.obs.samples <- rnorm(N, y.samples, y.obs.errors)
plot(x.samples, y.samples, asp = 1 )
plot(x.obs.samples, y.obs.samples, asp = 1 )
hist(y.samples,breaks=100)
hist(10^(x.samples),breaks=100)
cor(x.samples,y.samples)
cor(x.obs.samples,y.obs.samples)
# Create the stan model object
stanmodelcode <-'
data {
int<lower=0> N;
vector[N] obsx;
vector[N] obsy;
vector<lower=0>[N] sigmaobsx;
vector<lower=0>[N] sigmaobsy;
}
parameters {
real mu;
real alpha;
real beta1;
real<lower=0> sigma;
real<lower=0> sigmax;
vector[N] x;
vector[N] y;
}
model {
//priors
alpha ~ normal(0, 10);
beta1 ~ normal(0, 10);
sigma ~ uniform(0, 10);
sigmax ~ uniform(0, 10);
//likelihood
for (n in 1:N) {
x[n] ~ normal(mu, sigmax);
y[n] ~ normal(alpha + beta1 * x[n], sigma);
// Likelihood components
obsx[n] ~ normal(x[n], sigmaobsx[n]);
obsy[n] ~ normal(y[n], sigmaobsy[n]);
}
}
'
# Create the data list object
dat = list(N = N, obsy=y.obs.samples, obsx=x.obs.samples,sigmaobsy=y.obs.errors,sigmaobsx=x.obs.errors)
fit1 <- stan(model_code = stanmodelcode, chains = 1, data = dat, iter = 1, verbose = FALSE)
set.seed(12354)
fit2 = stan(fit=fit1 , data = dat,  iter = 5000  , warmup = 3000, chains = 3)
# summary
print(fit2, digits_summary=4)
full <- read.table("RRLyrae200Dambis.dat",header=TRUE,na.strings = "NA",
colClasses =c(rep("character",3),rep("numeric",6),"character",
rep("numeric",2),rep("character",1),rep("numeric",11)) )
n <- nrow(full)
full$K0    <- with(full, X.Kmag. - 0.114*AV )
full$em    <- with(full, e_.Kmag.) # Does not include uncertainty in dereddening
full$elogP <- with(full, LogP/(LogP*100) )
full$emet  <- with(full, 0.2*Met_Harris/(Met_Harris) )
#attach(full)
str(full)
full <- read.table("RRLyrae200Dambis.dat",header=TRUE,na.strings = "NA",
colClasses =c(rep("character",3),rep("numeric",6),"character",
rep("numeric",2),rep("character",1),rep("numeric",11)) )
n <- nrow(full)
full$K0    <- with(full, X.Kmag. - 0.114*AV )
full$em    <- with(full, e_.Kmag.) # Does not include uncertainty in dereddening
full$elogP <- with(full, LogP/(LogP*100) )
full$emet  <- with(full, 0.2*Met_Harris/(Met_Harris) )
#attach(full)
str(full)
stanPLZcode <-'
data {
int<lower=1> N; // number of observations
real pi[N];     // observed parallax
real m[N];      // observed apparent magnitude
real logP[N];   // decadic logarithm of observed period
#real alpha[N];  // observed right ascension
#real delta[N];  // observed declination
real met[N];    // observed metallicity
real AV[N];
real epi[N];    // measurement error of observed parallax
real em[N];     // measurement error of observed (reddened) apparent magnitude
real elogP[N];  // measurement error of logarithm of observed period
real ealpha[N]; // measurement error of observed right ascension
real edelta[N]; // measurement error of observed declination
real emet[N];   // uncertainty of observed metallicity
}
parameters {
vector<lower=0>[N] pi0;   // true parallax
vector[N] logP0;          // decadic logarithm of true period
vector[N] met0;           // true metallicity
vector[N] M;
real angle;
real b;
real c;
real beta;
real gamma;
real width;
#real eAV;
}
model {
real a;
real d;
vector[N] emtot;
width ~ exponential(1);
beta ~ normal(0.0,2.0);
gamma ~ exponential(1);
angle ~ normal(0,3.1416/2.0);
b ~ normal(0,3.0);
c ~ normal(0,3.1416/2.0);
a = tan(angle);
d = tan(c);
for (i in 1:N) {
pi0[i] ~ lognormal(beta,gamma);
logP0[i] ~ normal(0.0,2);
met0[i] ~ normal(0,5);
M[i] ~ normal(a*logP0[i] + d*met0[i] + b, width);
# likelihood
m[i] ~ normal(M[i] - (5.0*log10(pi0[i])) + 10.0 +AV[i] , em[i]);
pi[i] ~ normal(pi0[i], epi[i]);
logP[i] ~ normal(logP0[i],elogP[i]);
met[i] ~ normal(met0[i],emet[i]);
}
}
'
# Create data list object
linear_data <- list(N=nrow(full), pi=full$parallax, epi=full$parallax_error,
m=full$K0, em=full$em,
logP=full$LogP, elogP=full$elogP,
alpha=full$ra, delta=full$dec,
ealpha=full$ra_error, edelta=full$dec_error,
met=full$Met_Harris, emet=full$emet,
AV=full$AV
)
str(linear_data)
initf2 <- function(chain_id = 1) {
set.seed(chain_id)
# Create empty variables
initpi = rep(NA,n)
initlogp = rep(NA,n)
initmet = rep(NA,n)
initM = rep(NA,n)
# Initialize parameters
m=rnorm(1,0,1.0)
angle = atan(m)
b=rnorm(1,-1.0,0.3)
c = rnorm(1,0,0.5)
d = atan(c)
width=rexp(1,1.0)
beta=rnorm(1,0.0,2.0)
gamma=rexp(1,1.0)
eAV=rexp(1,1.0)
for (i in 1:n) {
initlogp[i] = rnorm(1,full$LogP[i],0.01)
initmet[i] = rnorm(1,full$Met_Harris,0.5)
initM[i] = rnorm(1, m*full$LogP[i] + c*full$Met_Harris[i] + b, width)
initpi[i] =  10^((initM[i]- full$K0[i]+10.0)/5.0) # Initialize almost at random (m,b,d can take almost any value)
}
list(pi0=initpi,
logP0=initlogp, M=initM,
angle=angle,
b=b, beta=beta, gamma=gamma, c=c, width=width,eAV=eAV)
}
# generate a list of lists to specify initial values
n_chains <- 4
init_ll <- lapply(1:n_chains, function(id) initf2(chain_id = id))
nsamples_chain =5000
nsamples <- n_chains*nsamples_chain/2
fit <- stan(model_code = stanPLZcode, data = linear_data, iter = nsamples_chain,
chains = n_chains,init=init_ll,control= list(adapt_delta = 0.8), verbose = TRUE,init_r=2)
pairs(fit, pars = c("width", "c", "b","angle"), labels=c("Intrinsic Width", "Metallicity Angle", "Intercept","log(P) Angle"),
log = FALSE, las = 1)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
setwd("~/Escritorio/astrometry-inference-tutorials/period-luminosity-relation")
